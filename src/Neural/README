Object Detection in Images

This example uses Retinanet which is an improvement over FasterRCNN because of its faster Focal Loss formula.
It uses the ResNet-50 backbone by default, which is acceptible for this example

This example uses keras-retinanet which lets you easily produce convolutional networks for computer vision applications.

But instead of using the standard keras and keras-retinanet packages, get the implementation from
https://github.com/fizyr/keras-retinanet/tree/disable-tf2-behavior

This is a specialized fork of the standard implementation that works better on Windows.
It must run over the specialized fork of the Keras package from
https://github.com/fizyr-forks/keras/tree/2.3.1.fizyr2

(See https://github.com/fizyr/keras-retinanet/issues/1171)


Training and Test Datasets

It is easier to organize the process if the training and test images are in separate directories.
Training should use all the training images and not reference the test images.
The images do not need to be processed before training.


Annotations

Keras retinanet assumes the images are not cropped to isolate the object of interest. The training script
expects a CSV formatted annotations file that defines bounding boxes for each image that isolates the objects.

If the training images are cropped, use the createAnnotations.py script to create an annotations file
with one bounding box around the whole image.

If the annotations are in XML format, the bounding boxes must be parsed to create the annotations file.
The XMLToAnnotations.py script is an example.

Test images should not be cropped since the model identifies all objects of interest in it.


Classes

The images classes are text labels so Keras retinanet needs a CSV formatted file that maps each image class
to a unique integer label.


Software Utilites

Keras retinanet provides a library for performing object detection and pre-written scripts for training.
It is suggested that you create a virtual environment (virtualenv or conda environemnt, for example)
to isolate the specialized requirements from other python projects.

*NOTE* virtualenv for Powershell users

To enter virtualenv in Powershell, execute Scripts\Activate.ps1 instead of sourcing the activate script.


Training

These specialized implementations run well on Windows but are not compatible with Tensorboard,
so the tensorboard directory should be set blank while training

(See https://github.com/fizyr/keras-retinanet/issues/1239)

retinanet-train --tensorboard-dir "" --epochs 25 --batch-size 4 --steps 50 --snapshot-path models csv annotations.csv classes.csv

Keras Retinanet uses the ResNet-50 backbone by default.
To use an alternate backbone, set the --backbone option, for example --backbone vgg16

- Convergence can be improved by adding a weights option with a predefined model, for example --weights resnet50_coco_best_v2.1.0.h5

- To continue training more epochs, set the weights option to a snapshot previously generated by the trainer


Export model for use

retinanet-convert-model  models/snapshot.h5  model.h5


Detecting objects using the exported model

Detect objects with the model using the example code from
https://github.com/fizyr/keras-retinanet/blob/master/examples/ResNet50RetinaNet.ipynb


Approaches to weapon detection

After brief experiments, it was concluded that for the default resnet50 backbone, transfer learning
with pre-trained weights converged faster in training but in testing, total misclassification loss was higher.

But training without weights converged at a high level of testing loss. That result was saved in weapon_scratch_model.h5

retinanet-train --tensorboard-dir "" --weights resnet50_coco_best_v2.1.0.h5 --batch-size 4 --epochs 5 --steps 25 --snapshot-path models csv person.csv classes.csv

retinanet-train --tensorboard-dir "" --backbone vgg16 --weights data/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5 --batch-size 4 --epochs 5 --steps 25 --snapshot-path models csv weapons.csv classes.c
sv
